! pip install -q sagemaker botocore boto3 awscli --upgrade

# Setup clients
import boto3

client = boto3.client(service_name="sagemaker", region_name='us-east-1')
runtime = boto3.client(service_name="sagemaker-runtime", region_name='us-east-1')

import boto3
import sagemaker
from sagemaker.estimator import Estimator

boto_session = boto3.session.Session()
region = boto_session.region_name
print(region)

sagemaker_session = sagemaker.Session()
bucket = 'eminisp500vbloise'
role = sagemaker.get_execution_role()
print(role)

base_job_prefix = "xgboost-example"
default_bucket = sagemaker_session.default_bucket()
s3_prefix = base_job_prefix

training_instance_type = "ml.m5.xlarge"

import numpy as np
import pandas as pd
from numpy import loadtxt
train_data_key_raw = '15-Micro-Emini-SP500-MES-F-granular.csv'
train_data_key = '15-Micro-Emini-SP500-MES-F-granular-poped.csv'
test_data_key = '15-Micro-Emini-SP500-MES-F-granular-outcome-poped.csv'
inference_data_key_raw = 'daily-granular-15.csv'
inference_data_key = 'daily-granular-15-poped.csv'
train_data_raw_location = 's3://{}/{}'.format(bucket, train_data_key_raw)
inference_data_raw_location = 's3://{}/{}'.format(bucket, inference_data_key_raw)
train_data_location = 's3://{}/{}'.format(bucket, train_data_key)
test_data_location = 's3://{}/{}'.format(bucket, test_data_key)
inference_data_location = 's3://{}/{}'.format(bucket, inference_data_key)

EminiSP = pd.read_csv(train_data_raw_location)
EminiSPpredict = pd.read_csv(inference_data_raw_location)
X = EminiSP.copy()
X.drop(['date-1', 'time-1', 'time-2', 'time-3', 'time-4', 'time-5', 'time-6', 'time-7', 'time-8', 'time-9', 'time-10', 'time-11', 'time-12', 'b_outcome'], axis=1, inplace=True) #,'percent-change-1', 'percent-change-2', 'percent-change-3'
y = EminiSP.pop('outcome')
EminiSPpredict.drop(['date-1', 'time-1', 'time-2', 'time-3', 'time-4', 'time-5', 'time-6', 'time-7', 'time-8', 'time-9', 'time-10', 'time-11', 'time-12'], axis=1, inplace=True) #,'percent-change-1', 'percent-change-2', 'percent-change-3'

X.to_csv(train_data_location, sep=',')
y.to_csv(test_data_location, sep=',')
EminiSPpredict.to_csv(inference_data_location, sep=',')

from sagemaker.inputs import TrainingInput

training_path = f"s3://{bucket}/15-Micro-Emini-SP500-MES-F-granular-poped.csv"
train_input = TrainingInput(training_path, content_type="text/csv")
test_path = f"s3://{bucket}/15-Micro-Emini-SP500-MES-F-granular-outcome-poped.csv"
test_input = TrainingInput(training_path, content_type="text/csv")

model_path = f"s3://{bucket}/{s3_prefix}/xgb_model"

# retrieve xgboost image
image_uri = sagemaker.image_uris.retrieve(
    framework="xgboost",
    region=region,
    version="1.0-1",
    py_version="py3",
    instance_type=training_instance_type,
)

# Configure Training Estimator
xgb_train = Estimator(
    image_uri=image_uri,
    instance_type=training_instance_type,
    instance_count=1,
    output_path=model_path,
    sagemaker_session=sagemaker_session,
    role=role,
)

# Set Hyperparameters
xgb_train.set_hyperparameters(
    objective="reg:squarederror",
    num_round=50,
    max_depth=5,
    eta=0.2,
    gamma=4,
    min_child_weight=6,
    subsample=0.7,
    silent=0,
)

# Fit model
# Splitting
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)
xgb_train.fit({"train": train_input})

# Retrieve model data from training job
model_artifacts = xgb_train.model_data
model_artifacts

from time import gmtime, strftime

model_name = "xgboost-serverless" + strftime("%Y-%m-%d-%H-%M-%S", gmtime())
print("Model name: " + model_name)

# dummy environment variables
byo_container_env_vars = {"SAGEMAKER_CONTAINER_LOG_LEVEL": "20", "SOME_ENV_VAR": "myEnvVar"}

create_model_response = client.create_model(
    ModelName=model_name,
    Containers=[
        {
            "Image": image_uri,
            "Mode": "SingleModel",
            "ModelDataUrl": model_artifacts,
            "Environment": byo_container_env_vars,
        }
    ],
    ExecutionRoleArn=role,
)

print("Model Arn: " + create_model_response["ModelArn"])

xgboost_epc_name = "xgboost-serverless-epc" + strftime("%Y-%m-%d-%H-%M-%S", gmtime())

endpoint_config_response = client.create_endpoint_config(
    EndpointConfigName=xgboost_epc_name,
    ProductionVariants=[
        {
            "VariantName": "byoVariant",
            "ModelName": model_name,
            "ServerlessConfig": {
                "MemorySizeInMB": 4096,
                "MaxConcurrency": 1,
            },
        },
    ],
)

print("Endpoint Configuration Arn: " + endpoint_config_response["EndpointConfigArn"])

endpoint_name = "xgboost-serverless-ep" + strftime("%Y-%m-%d-%H-%M-%S", gmtime())

create_endpoint_response = client.create_endpoint(
    EndpointName=endpoint_name,
    EndpointConfigName=xgboost_epc_name,
)

print("Endpoint Arn: " + create_endpoint_response["EndpointArn"])

# wait for endpoint to reach a terminal state (InService) using describe endpoint
import time

describe_endpoint_response = client.describe_endpoint(EndpointName=endpoint_name)

while describe_endpoint_response["EndpointStatus"] == "Creating":
    describe_endpoint_response = client.describe_endpoint(EndpointName=endpoint_name)
    print(describe_endpoint_response["EndpointStatus"])
    time.sleep(15)

describe_endpoint_response

import csv
from io import StringIO
s3client = boto3.client('s3')

bucket_name = 'eminisp500vbloise'

object_key = 'daily-granular-15-poped.csv'
csv_obj = s3client.get_object(Bucket=bucket_name, Key=object_key)
body = csv_obj['Body']
csv_string = body.read().decode('utf-8')
df = pd.read_csv(StringIO(csv_string))
x = df.to_string(header=False,
                  index=False,
                  index_names=False).split('\n')
vals = [','.join(ele.split()) for ele in x]
print(str(vals[0][2:]))
predict_path = inference_data_location

predict_input = str(vals[0][2:])
response = runtime.invoke_endpoint(
    EndpointName=endpoint_name,
    #Body=b"-0.5,-0.5,-2.25,-3.5,1980,-3.25,-1.75,0.0,1.5,969,1.5,2.0,-9.5,-2.75,54201,-3.0,3.25,4.75,-2.5,1629,-2.5,-5.5,-1.75,-0.25,-6185,-0.25,0.5,-4.5,-6.75,-13527,-6.75,-5.0,0.5,2.25,429,2.25,-4.5,-4.75,-6.0,-3264,-6.0,-1.5,-1.25,5.25,-13990,5.75,2.25,4.75,3.25,-9427,2.75,2.0,1.5,-2.25,5237,-2.0,1.75,2.25,4.25,-3157",
    #Body=b"-0.25,1.75,1.25,2.5,-100,2.5,1.0,1.0,-0.75,2120,-0.75,6.75,-1.25,6.0,44095,6.0,-0.75,-1.0,-4.5,-1061,-4.5,-1.75,1.5,0.75,-10718,1,-1.0,-4.75,-8.0,-3691,-8.25,-8.25,-4.25,2.75,6409,2.75,4.25,7,4.25,-15977,4.0,0.25,0.5,-3.25,-1350,-3.0,3.25,-2.5,6.75,1877,3.75,2,6.75,-2.5,-7253,0.25,-5.25,-5.0,-3.75,-1249",
    Body=predict_input,
    ContentType="text/csv",
)

print(response["Body"].read())

#Clean up
client.delete_model(ModelName=model_name)
client.delete_endpoint_config(EndpointConfigName=xgboost_epc_name)
client.delete_endpoint(EndpointName=endpoint_name)