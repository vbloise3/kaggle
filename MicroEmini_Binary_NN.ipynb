from pandas import read_csv
from keras.models import Sequential
from keras.layers import Dense
from keras.wrappers.scikit_learn import KerasClassifier
from sklearn.model_selection import cross_val_score
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import StratifiedKFold
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
import numpy as np
import tensorflow as tf
import pandas as pd
from google.colab import drive
from sklearn.model_selection import train_test_split
from keras import models
#from keras import layers
from tensorflow import keras
from tensorflow.keras import layers
#from keras import optimizers
from tensorflow.keras import optimizers
from keras.models import Input, Model
from keras.layers import Dense
from keras.layers import Dropout
import sys
if sys.version_info[0] < 3: 
    from StringIO import StringIO
else:
    from io import StringIO

# spread predictions

# Set scaled boolean
sclaled_on = True

drive.mount('/content/drive')
#!ls "/content/drive/My Drive/LSTM Futures"
!cp "/content/drive/My Drive/LSTM Futures/Micro-Emini-SP500-MES-F-granular.csv" "Micro-Emini-SP500-MES-F-granular.csv"
!cp "/content/drive/My Drive/LSTM Futures/daily-granular.csv" "daily-granular.csv"
EminiSP = pd.read_csv("/content/drive/My Drive/LSTM Futures/Micro-Emini-SP500-MES-F-granular.csv")
EminiSPpredicted = pd.read_csv("/content/drive/My Drive/LSTM Futures/daily-granular.csv")

X = EminiSP.copy()
X.drop(['date-1', 'time-1', 'time-2', 'time-3', 'time-4', 'time-5', 'outcome', 'b_outcome'], axis=1, inplace=True) #,'percent-change-1', 'percent-change-2', 'percent-change-3'
y = EminiSP.pop('b_outcome')
EminiSPpredict = EminiSPpredicted.copy()
EminiSPpredict.drop(['date-1', 'time-1', 'time-2', 'time-3', 'time-4', 'time-5'], axis=1, inplace=True) #,'percent-change-1', 'percent-change-2', 'percent-change-3'

print(X.head())
print(X.shape)

print(y.head())
print(y.shape)

print(EminiSPpredict.head())
print(EminiSPpredict.shape)

#
# Set up the network
#
#network = models.Sequential()
#network.add(layers.Dense(24, activation='relu', input_shape=(12,)))
#network.add(layers.Dense(32, activation='relu'))
#network.add(layers.Dense(32, activation='relu'))
#network.add(layers.Dense(32, activation='relu'))
#network.add(layers.Dense(32, activation='relu'))
#network.add(layers.Dense(1))

# Try Keras Functional API
#inputs = Input(shape=(25,))
#output = Dense(64, activation='linear')(inputs)
#linear_model = Model(inputs, output)
#linear_model.compile(optimizer='sgd', loss='mse')

# specify how many hidden layers to add (min 1)

'''
n_layers = 5

inputs = Input(shape=(25,))
x = Dense(200, activation='relu')(inputs)
#x = Dropout(0.4)(x)
for layer in range(n_layers - 1):
  x = Dense(200, activation='relu')(x)
  #x = Dropout(0.3)(x)
output = Dense(1, activation='sigmoid')(x)
deep_n_net = Model(inputs, output)
'''

#
# Configure the network with optimizer, loss function and accuracy
#
#network.compile(optimizer=optimizers.RMSprop(learning_rate=0.01),
#                loss='mse',
#                metrics=['mae'])
#
# Create training and test split
#
# Splitting
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)
#TESTDATA = StringIO("""open-1;high-1;low-1;close-1;volume-1;open-2;high-2;low-2;close-2;volume-2;open-3;high-3;low-3;close-3;volume-3;open-4;high-4;low-4;close-4;volume-4;open-5;high-5;low-5;close-5;volume-5
#  1;4348;4348;4346.25;4346.75;432;4355.75;4356.25;4353.5;4354.5;1576;4365.25;4366.25;4362.5;4363;2238;4351.5;4354.25;4350;4354;2804;4347;4348.25;4346.5;4347.5;1348
#  """)
#df_test = pd.read_csv(TESTDATA, sep=";")
#EminiSPpredict = df_test
# Scaling the data
# encode class values as integers
encoder = LabelEncoder()
encoder.fit(y)
encoded_y = encoder.transform(y)
encoder.fit(y_train)
encoded_y_train = encoder.transform(y_train)
encoder.fit(y_test)
encoded_y_test = encoder.transform(y_test)
from sklearn.preprocessing import MinMaxScaler

Target_scaler = MinMaxScaler(feature_range=(0, 1))
Feature_scaler = MinMaxScaler(feature_range=(0, 1))

X_train_scaled = Feature_scaler.fit_transform(np.array(X_train))
X_test_scaled = Feature_scaler.fit_transform(np.array(X_test))
X_scaled = Feature_scaler.fit_transform(np.array(X))

y_train_scaled = Target_scaler.fit_transform(np.array(encoded_y_train).reshape(-1,1))
y_test_scaled = Target_scaler.fit_transform(np.array(encoded_y_test).reshape(-1,1))
y_scaled = Target_scaler.fit_transform(np.array(encoded_y).reshape(-1,1))
EminiSPpredict_scaled = Feature_scaler.fit_transform(np.array(EminiSPpredict))

# encode class values as integers
encoder = LabelEncoder()
encoder.fit(y)
encoded_y = encoder.transform(y)
encoder.fit(y_train)
encoded_y_train = encoder.transform(y_train)
encoder.fit(y_test)
encoded_y_test = encoder.transform(y_test)

def create_baseline():
  # create model
  '''
  model = Sequential()
  model.add(Dense(25, input_dim=25, activation='relu'))
  model.add(Dense(25, input_dim=25, activation='relu'))
  model.add(Dense(1, activation='sigmoid'))
  '''
  n_layers = 5
  inputs = Input(shape=(25,))
  x = Dense(25, activation='relu')(inputs)
  #x = Dropout(0.4)(x)
  for layer in range(n_layers - 1):
    x = Dense(25, activation='relu')(x)
    #x = Dropout(0.3)(x)
  output = Dense(1, activation='sigmoid')(x)
  model = Model(inputs, output)
  # Compile model
  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
  return model

# functional model
#deep_n_net.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01,
#    beta_1=0.9,
#    beta_2=0.999,
#    epsilon=1e-07,
#    amsgrad=False,
#    name="Adam"), loss= 'mse', metrics=['mae'])

#deep_n_net.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.01,
#    beta_1=0.9,
#    beta_2=0.999,
#    epsilon=1e-07,
#    amsgrad=False,
#    name="Adam"), metrics=['accuracy'])

# evaluate model with standardized dataset
estimator = KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=0)
kfold = StratifiedKFold(n_splits=10, shuffle=True)
results = cross_val_score(estimator, X_train_scaled, encoded_y_train, cv=kfold)
# evaluate baseline model with standardized dataset
#estimators = []
#estimators.append(('standardize', StandardScaler()))
#estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=0))) #build_fn=create_baseline
#pipeline = Pipeline(estimators)
#kfold = StratifiedKFold(n_splits=10, shuffle=True)
#results = cross_val_score(pipeline, X_train_scaled, encoded_y_train, cv=kfold)
print("Baseline: %.2f%% (%.2f%%)" % (results.mean()*100, results.std()*100))
estimator.fit(X_train_scaled, encoded_y_train)
pred = estimator.predict(EminiSPpredict_scaled) #EminiSPpredict_scaled or X_test_scaled
pred_rescaled = Target_scaler.inverse_transform(pred)
print("Prediction: ", pred_rescaled)

