
# First XGBoost model for Pima Indians dataset
from sklearn.preprocessing import LabelEncoder
import numpy as np
import pandas as pd
from numpy import loadtxt
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from google.colab import drive
from sklearn.metrics import mean_squared_error as MSE
# Set scaled boolean
sclaled_on = True

drive.mount('/content/drive')
#!ls "/content/drive/My Drive/LSTM Futures"
!cp "/content/drive/My Drive/LSTM Futures/Micro-Emini-SP500-MES-F-granular.csv" "Micro-Emini-SP500-MES-F-granular.csv"
!cp "/content/drive/My Drive/LSTM Futures/daily-granular.csv" "daily-granular.csv"
EminiSP = pd.read_csv("/content/drive/My Drive/LSTM Futures/Micro-Emini-SP500-MES-F-granular.csv")
EminiSPpredict = pd.read_csv("/content/drive/My Drive/LSTM Futures/daily-granular.csv")

X = EminiSP.copy()
X.drop(['date-1', 'time-1', 'time-2', 'time-3', 'time-4', 'time-5', 'outcome', 'b_outcome'], axis=1, inplace=True) #,'percent-change-1', 'percent-change-2', 'percent-change-3'
Y = EminiSP.pop('b_outcome')
EminiSPpredict.drop(['date-1', 'time-1', 'time-2', 'time-3', 'time-4', 'time-5'], axis=1, inplace=True) #,'percent-change-1', 'percent-change-2', 'percent-change-3'

print(X.head())
print(X.shape)

print(Y.head())
print(Y.shape)

# split data into X and y
#X = dataset[:,0:25]
#Y = dataset[:,25]
# split data into train and test sets
seed = 7
test_size = 0.33
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)
# Scaling the data
# encode class values as integers
encoder = LabelEncoder()
encoder.fit(Y)
encoded_y = encoder.transform(Y)
encoder.fit(y_train)
encoded_y_train = encoder.transform(y_train)
encoder.fit(y_test)
encoded_y_test = encoder.transform(y_test)
from sklearn.preprocessing import MinMaxScaler

Target_scaler = MinMaxScaler(feature_range=(0, 1))
Feature_scaler = MinMaxScaler(feature_range=(0, 1))

X_train_scaled = Feature_scaler.fit_transform(np.array(X_train))
X_test_scaled = Feature_scaler.fit_transform(np.array(X_test))

y_train_scaled = Target_scaler.fit_transform(np.array(encoded_y_train).reshape(-1,1))
y_test_scaled = Target_scaler.fit_transform(np.array(encoded_y_test).reshape(-1,1))
EminiSPpredict_scaled = Feature_scaler.fit_transform(np.array(EminiSPpredict))

# fit model no training data
model = XGBClassifier()
if not sclaled_on:
  model.fit(X_train, encoded_y_train)
  # make predictions for test data
  y_pred = model.predict(X_test)
else:
  model.fit(X_train_scaled, encoded_y_train)
  # make predictions for test data
  y_pred = model.predict(X_test_scaled)
predictions = [round(value) for value in y_pred]
# evaluate predictions
accuracy = accuracy_score(encoded_y_test, predictions)
print("Accuracy: %.2f%%" % (accuracy * 100.0))
if not sclaled_on:  
  # Predict the model
  pred = model.predict(EminiSPpredict)
  print("Prediction : % f" %(pred))
  # RMSE Computation
  #rmse = np.sqrt(MSE(y_test, pred))
  #print("RMSE : % f" %(rmse))
else:
  # scaled
  pred = model.predict(EminiSPpredict_scaled)
  pred_rescaled = Target_scaler.inverse_transform(pred.reshape(1,-1))
  print("Prediction : % f" %(pred_rescaled))
  # RMSE Computation
  #rmse = np.sqrt(MSE(y_test_scaled, pred))
  #print("RMSE : % f" %(rmse))