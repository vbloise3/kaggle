import numpy as np
import tensorflow as tf
import pandas as pd
from google.colab import drive
from sklearn.model_selection import train_test_split
from keras import models
from keras import layers
#from keras import optimizers
from tensorflow.keras import optimizers
from keras.models import Input, Model
from keras.layers import Dense
from keras.layers import Dropout
import keras as keras

#model = keras.Sequential([
#    keras.layers.Dense(64, activation=tf.nn.relu, input_shape=[1]),
#    keras.layers.Dense(64, activation=tf.nn.relu),
#    keras.layers.Dense(1)
#  ])

# specify how many hidden layers to add (min 1)
n_layers = 5

inputs = Input(shape=(1,))
x = Dense(200, activation='relu')(inputs)
#x = Dropout(0.4)(x)
for layer in range(n_layers - 1):
  x = Dense(200, activation='relu')(x)
  #x = Dropout(0.3)(x)
output = Dense(1, activation='linear')(x)
deep_n_net = Model(inputs, output)

#optimizer = tf.keras.optimizers.RMSprop(0.001)

#optimizer = tf.keras.optimizers.RMSprop(0.001)

#model.compile(loss='mean_squared_error',
#                optimizer=optimizer,
#                metrics=['mean_absolute_error', 'mean_squared_error'])
deep_n_net.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01,
    beta_1=0.9,
    beta_2=0.999,
    epsilon=1e-07,
    amsgrad=False,
    name="Adam"), loss= 'mse', metrics=['mae'])


Fahrenheit=np.array([-140,-136,-124,-112,-105,-96,-88,-75,-63,-60,-58,-40,-20,-10,0,30,35,48,55,69,81,89,95,99,105,110,120,135,145,158,160],dtype=float)

Celsius=np.array([-95.55,-93.33,-86.66,-80,-76.11,-71.11,-66.66,-59.44,-52.77,-51.11,-50,-40,-28.88,-23.33,-17.77,-1.11,1.66,8.88,12,20,27.22,31.66,35,37.22,40.55,43.33,48.88,57.22,62.77,70,71.11],dtype=float)

EminiSPpredict = [160]

X_train, X_test, y_train, y_test = train_test_split(Fahrenheit, Celsius, test_size=0.1, random_state=42)

history = deep_n_net.fit(X_train, y_train, epochs = 100, verbose=1, validation_data = (X_test, y_test))
#model.fit(Fahrenheit,Celsius,epochs=500)

#model.predict([-140])
import matplotlib.pyplot as plt
 
history_dict = history.history
loss_values = history_dict['loss']
val_loss_values = history_dict['val_loss']
accuracy = history_dict['mae']
val_accuracy = history_dict['val_mae']
 
epochs = range(1, len(loss_values) + 1)
fig, ax = plt.subplots(1, 2, figsize=(14, 6))
#
# Plot the model accuracy (MAE) vs Epochs
#
ax[0].plot(epochs, accuracy, 'bo', label='Training accuracy')
ax[0].plot(epochs, val_accuracy, 'b', label='Validation accuracy')
ax[0].set_title('Training & Validation Accuracy', fontsize=16)
ax[0].set_xlabel('Epochs', fontsize=16)
ax[0].set_ylabel('Accuracy', fontsize=16)
ax[0].legend()
#
# Plot the loss vs Epochs
#
ax[1].plot(epochs, loss_values, 'bo', label='Training loss')
ax[1].plot(epochs, val_loss_values, 'b', label='Validation loss')
ax[1].set_title('Training & Validation Loss', fontsize=16)
ax[1].set_xlabel('Epochs', fontsize=16)
ax[1].set_ylabel('Loss', fontsize=16)
ax[1].legend()

# make predictions
y_pred = deep_n_net.predict(EminiSPpredict)
print(y_pred)